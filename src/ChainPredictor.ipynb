{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "creative-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweet_sent_predictor.predictor.ChainPredictor import ChainPredictor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tweet_sent_predictor.transformer.LowerCaseTransformer import LowerCaseTransformer\n",
    "from tweet_sent_predictor.transformer.MentionFlagger import MentionFlagger\n",
    "from tweet_sent_predictor.transformer.NumberFlagger import NumberFlagger\n",
    "from tweet_sent_predictor.transformer.SplitterPunctuation import SplitterPunctuation, split_punctuation\n",
    "from tweet_sent_predictor.transformer.URLFlagger import URLFlagger\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tweet_sent_predictor.transformer.StopWordFilter import StopWordFilter\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "employed-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) # for reproducibility with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bridal-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_col = \"opinion\"\n",
    "brand_col = \"brand\"\n",
    "text_col = \"body\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-albania",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dynamic-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tweet_sent_predictor/data/train_proper.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accomplished-morning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opinion</th>\n",
       "      <th>brand</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neu</td>\n",
       "      <td>apl</td>\n",
       "      <td>20 min line @apple store @short pump.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>irr</td>\n",
       "      <td>msf</td>\n",
       "      <td>Nueva tecnología convierte cualquier superfici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neu</td>\n",
       "      <td>ggl</td>\n",
       "      <td>Some people should not post replies in #Google...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>apl</td>\n",
       "      <td>I know a few others having same issue RT @Joel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>msf</td>\n",
       "      <td>#Microsoft - We put the \"\"backwards\"\" into bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>neu</td>\n",
       "      <td>twt</td>\n",
       "      <td>Twitter Buzz Builds for the Occupy Wall Street...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>neg</td>\n",
       "      <td>msf</td>\n",
       "      <td>#Google Apps vs. #Microsoft #Office 365: \"\"it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>pos</td>\n",
       "      <td>apl</td>\n",
       "      <td>This good here iPhone will do me VERY well tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>irr</td>\n",
       "      <td>msf</td>\n",
       "      <td>#Microsoft ofrece un sistema de #codificación ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>irr</td>\n",
       "      <td>msf</td>\n",
       "      <td>#Job #ICT Sachbearbeiter Immobilienbewirtschaf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   opinion brand                                               body\n",
       "0      neu   apl              20 min line @apple store @short pump.\n",
       "1      irr   msf  Nueva tecnología convierte cualquier superfici...\n",
       "2      neu   ggl  Some people should not post replies in #Google...\n",
       "3      neg   apl  I know a few others having same issue RT @Joel...\n",
       "4      neg   msf  #Microsoft - We put the \"\"backwards\"\" into bac...\n",
       "..     ...   ...                                                ...\n",
       "95     neu   twt  Twitter Buzz Builds for the Occupy Wall Street...\n",
       "96     neg   msf  #Google Apps vs. #Microsoft #Office 365: \"\"it ...\n",
       "97     pos   apl  This good here iPhone will do me VERY well tod...\n",
       "98     irr   msf  #Microsoft ofrece un sistema de #codificación ...\n",
       "99     irr   msf  #Job #ICT Sachbearbeiter Immobilienbewirtschaf...\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "selected-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"body\"]\n",
    "y = df[\"opinion\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "practical-means",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 20 min line @apple store @short pump.\n",
       "1     Nueva tecnología convierte cualquier superfici...\n",
       "2     Some people should not post replies in #Google...\n",
       "3     I know a few others having same issue RT @Joel...\n",
       "4     #Microsoft - We put the \"\"backwards\"\" into bac...\n",
       "                            ...                        \n",
       "95    Twitter Buzz Builds for the Occupy Wall Street...\n",
       "96    #Google Apps vs. #Microsoft #Office 365: \"\"it ...\n",
       "97    This good here iPhone will do me VERY well tod...\n",
       "98    #Microsoft ofrece un sistema de #codificación ...\n",
       "99    #Job #ICT Sachbearbeiter Immobilienbewirtschaf...\n",
       "Name: body, Length: 100, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wicked-cleaner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neu', 'irr', 'neu', 'neg', 'neg', 'neg', 'neu', 'irr', 'neu',\n",
       "       'irr', 'neu', 'neg', 'neu', 'neu', 'pos', 'neu', 'neu', 'pos',\n",
       "       'neu', 'irr', 'neu', 'irr', 'neu', 'neg', 'irr', 'neg', 'irr',\n",
       "       'neg', 'neu', 'irr', 'neu', 'pos', 'neg', 'neu', 'irr', 'irr',\n",
       "       'neu', 'irr', 'irr', 'neu', 'irr', 'neu', 'irr', 'neu', 'neg',\n",
       "       'neu', 'irr', 'pos', 'neu', 'neu', 'irr', 'irr', 'neu', 'neu',\n",
       "       'neu', 'neu', 'irr', 'irr', 'neg', 'neu', 'neu', 'pos', 'neu',\n",
       "       'neu', 'pos', 'neu', 'irr', 'irr', 'irr', 'neu', 'neu', 'irr',\n",
       "       'irr', 'irr', 'neu', 'neu', 'irr', 'neu', 'neu', 'pos', 'irr',\n",
       "       'neu', 'irr', 'neg', 'irr', 'neg', 'neu', 'neu', 'neu', 'pos',\n",
       "       'pos', 'neu', 'irr', 'pos', 'irr', 'neu', 'neg', 'pos', 'irr',\n",
       "       'irr'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-antibody",
   "metadata": {},
   "source": [
    "## Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-glucose",
   "metadata": {},
   "source": [
    "### Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "historic-reliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "0.96  accuracy on train set\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "[0.6  0.6  0.55 0.6  0.75]\n",
      "0.62 0.004599999999999999\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"Lowercase\", LowerCaseTransformer()),\n",
    "    (\"MentionFlagger\", MentionFlagger()),\n",
    "    (\"URLFlagger\", URLFlagger()),\n",
    "    (\"NumberFlagger\", NumberFlagger()),\n",
    "    (\"StopwordFilter\", StopWordFilter()),\n",
    "    #(\"count\", CountVectorizer(analyzer=lambda x:x),\n",
    "    (\"count\", CountVectorizer(analyzer=\"word\", tokenizer=split_punctuation, ngram_range=(1,3)))\n",
    "])\n",
    "\n",
    "clf = MultinomialNB()\n",
    "\n",
    "predictor = ChainPredictor(pipe=pipe, clf=clf)\n",
    "predictor.fit(X, y)\n",
    "print(predictor.score(X, y), \" accuracy on train set\")\n",
    "scores = cross_val_score(predictor, X, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean(), scores.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-christopher",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "regular-talent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "1.0  accuracy on train set\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "[0.5  0.5  0.45 0.5  0.6 ]\n",
      "0.51 0.002399999999999999\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"Lowercase\", LowerCaseTransformer()),\n",
    "    (\"MentionFlagger\", MentionFlagger()),\n",
    "    (\"URLFlagger\", URLFlagger()),\n",
    "    (\"NumberFlagger\", NumberFlagger()),\n",
    "    (\"StopwordFilter\", StopWordFilter()),\n",
    "    #(\"count\", CountVectorizer(analyzer=lambda x:x),\n",
    "    (\"count\", CountVectorizer(analyzer=\"word\", tokenizer=split_punctuation, ngram_range=(1,3)))\n",
    "])\n",
    "\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", alpha=1e-3)\n",
    "\n",
    "predictor = ChainPredictor(pipe=pipe, clf=clf)\n",
    "predictor.fit(X, y)\n",
    "print(predictor.score(X, y), \" accuracy on train set\")\n",
    "scores = cross_val_score(predictor, X, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean(), scores.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-glucose",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "\n",
    "#### Liblinear + One versus rest scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aquatic-uruguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "0.99  accuracy on train set\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "[0.6  0.6  0.5  0.55 0.55]\n",
      "0.5599999999999999 0.001399999999999999\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"Lowercase\", LowerCaseTransformer()),\n",
    "    (\"MentionFlagger\", MentionFlagger()),\n",
    "    (\"URLFlagger\", URLFlagger()),\n",
    "    (\"NumberFlagger\", NumberFlagger()),\n",
    "    (\"StopwordFilter\", StopWordFilter()),\n",
    "    (\"count\", CountVectorizer(analyzer=\"word\", tokenizer=split_punctuation, ngram_range=(1,3)))\n",
    "])\n",
    "\n",
    "clf = LogisticRegression(solver=\"liblinear\")\n",
    "\n",
    "predictor = ChainPredictor(pipe=pipe, clf=clf)\n",
    "predictor.fit(X, y)\n",
    "print(predictor.score(X, y), \" accuracy on train set\")\n",
    "scores = cross_val_score(predictor, X, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean(), scores.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-bermuda",
   "metadata": {},
   "source": [
    "#### newton cg + multinomial loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "modern-argument",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "0.9439252336448598  accuracy on train set\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "[0.74850299 0.74491018 0.78682635 0.78297362 0.77098321]\n",
      "0.7668392710980917 0.000298815366593932\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"Lowercase\", LowerCaseTransformer()),\n",
    "    (\"MentionFlagger\", MentionFlagger()),\n",
    "    (\"URLFlagger\", URLFlagger()),\n",
    "    (\"NumberFlagger\", NumberFlagger()),\n",
    "    (\"StopwordFilter\", StopWordFilter()),\n",
    "    (\"count\", CountVectorizer(analyzer=\"word\", tokenizer=split_punctuation, ngram_range=(1,3))),\n",
    "    (\"Maxent\", LogisticRegression(solver=\"newton-cg\"))\n",
    "])\n",
    "\n",
    "predictor = SmartPredictor(pipe=pipe)\n",
    "predictor.fit(X, y)\n",
    "print(predictor.score(X, y), \" accuracy on train set\")\n",
    "scores = cross_val_score(predictor, X, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean(), scores.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-jimmy",
   "metadata": {},
   "source": [
    "#### Lbfgs + multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "constant-manhattan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "1.0  accuracy on train set\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "[0.55 0.6  0.55 0.5  0.45]\n",
      "0.53 0.0026\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"Lowercase\", LowerCaseTransformer()),\n",
    "    (\"MentionFlagger\", MentionFlagger()),\n",
    "    (\"URLFlagger\", URLFlagger()),\n",
    "    (\"NumberFlagger\", NumberFlagger()),\n",
    "    (\"StopwordFilter\", StopWordFilter()),\n",
    "    (\"count\", CountVectorizer(analyzer=\"word\", tokenizer=split_punctuation, ngram_range=(1,3)))\n",
    "])\n",
    "\n",
    "clf = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "predictor = ChainPredictor(pipe=pipe, clf=clf)\n",
    "predictor.fit(X, y)\n",
    "print(predictor.score(X, y), \" accuracy on train set\")\n",
    "scores = cross_val_score(predictor, X, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean(), scores.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-princeton",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "vertical-analysis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "exposed-exclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "1.0  accuracy on train set\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "[0.55 0.6  0.55 0.5  0.45]\n",
      "0.53 0.0026\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"Lowercase\", LowerCaseTransformer()),\n",
    "    (\"MentionFlagger\", MentionFlagger()),\n",
    "    (\"URLFlagger\", URLFlagger()),\n",
    "    (\"NumberFlagger\", NumberFlagger()),\n",
    "    (\"StopwordFilter\", StopWordFilter()),\n",
    "    (\"count\", CountVectorizer(analyzer=\"word\", tokenizer=split_punctuation, ngram_range=(1,3)))\n",
    "])\n",
    "\n",
    "predictor = ChainPredictor(pipe=pipe, clf=clf)\n",
    "predictor.fit(X, y)\n",
    "print(predictor.score(X, y), \" accuracy on train set\")\n",
    "scores = cross_val_score(predictor, X, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean(), scores.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-disaster",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "#### Multi softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "impaired-curve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'multi:softmax',\n",
       " 'use_label_encoder': True,\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'importance_type': 'gain',\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBClassifier(objective=\"multi:softmax\")\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "curious-plymouth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "1.0  accuracy on train set\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "[0.55 0.6  0.55 0.5  0.45]\n",
      "0.53 0.0026\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"Lowercase\", LowerCaseTransformer()),\n",
    "    (\"MentionFlagger\", MentionFlagger()),\n",
    "    (\"URLFlagger\", URLFlagger()),\n",
    "    (\"NumberFlagger\", NumberFlagger()),\n",
    "    (\"StopwordFilter\", StopWordFilter()),\n",
    "    (\"count\", CountVectorizer(analyzer=\"word\", tokenizer=split_punctuation, ngram_range=(1,3)))\n",
    "])\n",
    "\n",
    "predictor = ChainPredictor(pipe=pipe, clf=clf)\n",
    "predictor.fit(X, y)\n",
    "print(predictor.score(X, y), \" accuracy on train set\")\n",
    "scores = cross_val_score(predictor, X, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean(), scores.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-boutique",
   "metadata": {},
   "source": [
    "#### Multi softprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "biological-importance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'multi:softprob',\n",
       " 'use_label_encoder': True,\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'importance_type': 'gain',\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBClassifier(objective=\"multi:softprob\")\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "exposed-failure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit\n",
      "1.0  accuracy on train set\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "[0.55 0.6  0.55 0.5  0.45]\n",
      "0.53 0.0026\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"Lowercase\", LowerCaseTransformer()),\n",
    "    (\"MentionFlagger\", MentionFlagger()),\n",
    "    (\"URLFlagger\", URLFlagger()),\n",
    "    (\"NumberFlagger\", NumberFlagger()),\n",
    "    (\"StopwordFilter\", StopWordFilter()),\n",
    "    (\"count\", CountVectorizer(analyzer=\"word\", tokenizer=split_punctuation, ngram_range=(1,3)))\n",
    "])\n",
    "\n",
    "predictor = ChainPredictor(pipe=pipe, clf=clf)\n",
    "predictor.fit(X, y)\n",
    "print(predictor.score(X, y), \" accuracy on train set\")\n",
    "scores = cross_val_score(predictor, X, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean(), scores.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
