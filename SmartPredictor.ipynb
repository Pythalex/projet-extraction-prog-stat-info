{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "trying-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictor.SmartPredictor import SmartPredictor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from transformer.LowerCaseTransformer import LowerCaseTransformer\n",
    "from transformer.MentionFlagger import MentionFlagger\n",
    "from transformer.NumberFlagger import NumberFlagger\n",
    "from transformer.SplitterPunctuation import SplitterPunctuation, split_punctuation\n",
    "from transformer.URLFlagger import URLFlagger\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformer.StopWordFilter import StopWordFilter\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "frank-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) # for reproducibility with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "discrete-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_col = \"opinion\"\n",
    "brand_col = \"brand\"\n",
    "text_col = \"body\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-sunrise",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "indirect-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_proper.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "egyptian-apparel",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     opinion brand                                               body\n",
       "0        neu   apl              20 min line @apple store @short pump.\n",
       "1        irr   msf  Nueva tecnología convierte cualquier superfici...\n",
       "2        neu   ggl  Some people should not post replies in #Google...\n",
       "3        neg   apl  I know a few others having same issue RT @Joel...\n",
       "4        neg   msf  #Microsoft - We put the \"\"backwards\"\" into bac...\n",
       "...      ...   ...                                                ...\n",
       "4168     neg   apl  fuck this see you hoes @ work @WeakTwip @Munnn...\n",
       "4169     neg   msf  #Microsoft, #Adobe lose $13.5bn to piracy: Rep...\n",
       "4170     neu   twt  I tried to explain why you would do \"\"The #Twi...\n",
       "4171     neg   apl  Installed io5 - fine on ipad but wiped wife's ...\n",
       "4172     neg   msf  #microsoft #careers site is giving errors for ...\n",
       "\n",
       "[4173 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>opinion</th>\n      <th>brand</th>\n      <th>body</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>neu</td>\n      <td>apl</td>\n      <td>20 min line @apple store @short pump.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>irr</td>\n      <td>msf</td>\n      <td>Nueva tecnología convierte cualquier superfici...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>neu</td>\n      <td>ggl</td>\n      <td>Some people should not post replies in #Google...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>neg</td>\n      <td>apl</td>\n      <td>I know a few others having same issue RT @Joel...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>neg</td>\n      <td>msf</td>\n      <td>#Microsoft - We put the \"\"backwards\"\" into bac...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4168</th>\n      <td>neg</td>\n      <td>apl</td>\n      <td>fuck this see you hoes @ work @WeakTwip @Munnn...</td>\n    </tr>\n    <tr>\n      <th>4169</th>\n      <td>neg</td>\n      <td>msf</td>\n      <td>#Microsoft, #Adobe lose $13.5bn to piracy: Rep...</td>\n    </tr>\n    <tr>\n      <th>4170</th>\n      <td>neu</td>\n      <td>twt</td>\n      <td>I tried to explain why you would do \"\"The #Twi...</td>\n    </tr>\n    <tr>\n      <th>4171</th>\n      <td>neg</td>\n      <td>apl</td>\n      <td>Installed io5 - fine on ipad but wiped wife's ...</td>\n    </tr>\n    <tr>\n      <th>4172</th>\n      <td>neg</td>\n      <td>msf</td>\n      <td>#microsoft #careers site is giving errors for ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>4173 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "scenic-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"body\"]\n",
    "y = df[\"opinion\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "expected-spanking",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0                   20 min line @apple store @short pump.\n",
       "1       Nueva tecnología convierte cualquier superfici...\n",
       "2       Some people should not post replies in #Google...\n",
       "3       I know a few others having same issue RT @Joel...\n",
       "4       #Microsoft - We put the \"\"backwards\"\" into bac...\n",
       "                              ...                        \n",
       "4168    fuck this see you hoes @ work @WeakTwip @Munnn...\n",
       "4169    #Microsoft, #Adobe lose $13.5bn to piracy: Rep...\n",
       "4170    I tried to explain why you would do \"\"The #Twi...\n",
       "4171    Installed io5 - fine on ipad but wiped wife's ...\n",
       "4172    #microsoft #careers site is giving errors for ...\n",
       "Name: body, Length: 4173, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mediterranean-preservation",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['neu', 'irr', 'neu', ..., 'neu', 'neg', 'neg'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-florist",
   "metadata": {},
   "source": [
    "## Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-annual",
   "metadata": {},
   "source": [
    "### Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fallen-remark",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fit\n",
      "0.9329019889767554  accuracy on train set\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "[0.74730539 0.74610778 0.75928144 0.76858513 0.75539568]\n",
      "0.755335085225233 6.815204001228885e-05\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"Lowercase\", LowerCaseTransformer()),\n",
    "    (\"MentionFlagger\", MentionFlagger()),\n",
    "    (\"URLFlagger\", URLFlagger()),\n",
    "    (\"NumberFlagger\", NumberFlagger()),\n",
    "    (\"StopwordFilter\", StopWordFilter()),\n",
    "    #(\"count\", CountVectorizer(analyzer=lambda x:x),\n",
    "    (\"count\", CountVectorizer(analyzer=\"word\", tokenizer=split_punctuation, ngram_range=(1,3))),\n",
    "    (\"Bayesian\", MultinomialNB())\n",
    "])\n",
    "\n",
    "predictor = SmartPredictor(pipe=pipe)\n",
    "predictor.fit(X, y)\n",
    "print(predictor.score(X, y), \" accuracy on train set\")\n",
    "scores = cross_val_score(predictor, X, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean(), scores.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-decline",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vital-disney",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fit\n",
      "0.8873711957824107  accuracy on train set\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "[0.71137725 0.71137725 0.72215569 0.73501199 0.72302158]\n",
      "0.720588750556441 7.722149311836644e-05\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"Lowercase\", LowerCaseTransformer()),\n",
    "    (\"MentionFlagger\", MentionFlagger()),\n",
    "    (\"URLFlagger\", URLFlagger()),\n",
    "    (\"NumberFlagger\", NumberFlagger()),\n",
    "    (\"StopwordFilter\", StopWordFilter()),\n",
    "    #(\"count\", CountVectorizer(analyzer=lambda x:x),\n",
    "    (\"count\", CountVectorizer(analyzer=\"word\", tokenizer=split_punctuation, ngram_range=(1,3))),\n",
    "    (\"SVM\", SVC())\n",
    "])\n",
    "\n",
    "predictor = SmartPredictor(pipe=pipe)\n",
    "predictor.fit(X, y)\n",
    "print(predictor.score(X, y), \" accuracy on train set\")\n",
    "scores = cross_val_score(predictor, X, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean(), scores.var())"
   ]
  },
  {
   "source": [
    "### Logistic regression\n",
    "\n",
    "#### Liblinear + One versus rest scheme"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fit\n",
      "0.9374550682961897  accuracy on train set\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "[0.73652695 0.74850299 0.77964072 0.79016787 0.75899281]\n",
      "0.7627662660290929 0.00038835533085022304\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"Lowercase\", LowerCaseTransformer()),\n",
    "    (\"MentionFlagger\", MentionFlagger()),\n",
    "    (\"URLFlagger\", URLFlagger()),\n",
    "    (\"NumberFlagger\", NumberFlagger()),\n",
    "    (\"StopwordFilter\", StopWordFilter()),\n",
    "    (\"count\", CountVectorizer(analyzer=\"word\", tokenizer=split_punctuation, ngram_range=(1,3))),\n",
    "    (\"Maxent\", LogisticRegression(solver=\"liblinear\")) # good solver for small dataset\n",
    "])\n",
    "\n",
    "predictor = SmartPredictor(pipe=pipe)\n",
    "predictor.fit(X, y)\n",
    "print(predictor.score(X, y), \" accuracy on train set\")\n",
    "scores = cross_val_score(predictor, X, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean(), scores.var())"
   ]
  },
  {
   "source": [
    "#### newton cg + multinomial loss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fit\n",
      "0.9379343398034987  accuracy on train set\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "[0.73892216 0.7497006  0.77724551 0.78896882 0.75779376]\n",
      "0.7625261706802222 0.000331982673140113\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"Lowercase\", LowerCaseTransformer()),\n",
    "    (\"MentionFlagger\", MentionFlagger()),\n",
    "    (\"URLFlagger\", URLFlagger()),\n",
    "    (\"NumberFlagger\", NumberFlagger()),\n",
    "    (\"StopwordFilter\", StopWordFilter()),\n",
    "    (\"count\", CountVectorizer(analyzer=\"word\", tokenizer=split_punctuation, ngram_range=(1,3))),\n",
    "    (\"Maxent\", LogisticRegression(solver=\"newton-cg\"))\n",
    "])\n",
    "\n",
    "predictor = SmartPredictor(pipe=pipe)\n",
    "predictor.fit(X, y)\n",
    "print(predictor.score(X, y), \" accuracy on train set\")\n",
    "scores = cross_val_score(predictor, X, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean(), scores.var())"
   ]
  },
  {
   "source": [
    "#### Lbfgs + multinomial"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fit\n",
      "0.9379343398034987  accuracy on train set\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "[0.73892216 0.7497006  0.77724551 0.78896882 0.75779376]\n",
      "0.7625261706802222 0.000331982673140113\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"Lowercase\", LowerCaseTransformer()),\n",
    "    (\"MentionFlagger\", MentionFlagger()),\n",
    "    (\"URLFlagger\", URLFlagger()),\n",
    "    (\"NumberFlagger\", NumberFlagger()),\n",
    "    (\"StopwordFilter\", StopWordFilter()),\n",
    "    (\"count\", CountVectorizer(analyzer=\"word\", tokenizer=split_punctuation, ngram_range=(1,3))),\n",
    "    (\"Maxent\", LogisticRegression(solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "predictor = SmartPredictor(pipe=pipe)\n",
    "predictor.fit(X, y)\n",
    "print(predictor.score(X, y), \" accuracy on train set\")\n",
    "scores = cross_val_score(predictor, X, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean(), scores.var())"
   ]
  },
  {
   "source": [
    "### Random forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fit\n",
      "0.9376947040498442  accuracy on train set\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "fit\n",
      "[0.71616766 0.72215569 0.74131737 0.74940048 0.73021583]\n",
      "0.7318514051034621 0.00014804723295718563\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"Lowercase\", LowerCaseTransformer()),\n",
    "    (\"MentionFlagger\", MentionFlagger()),\n",
    "    (\"URLFlagger\", URLFlagger()),\n",
    "    (\"NumberFlagger\", NumberFlagger()),\n",
    "    (\"StopwordFilter\", StopWordFilter()),\n",
    "    (\"count\", CountVectorizer(analyzer=\"word\", tokenizer=split_punctuation, ngram_range=(1,3))),\n",
    "    (\"RF\", clf) # default\n",
    "])\n",
    "\n",
    "predictor = SmartPredictor(pipe=pipe)\n",
    "predictor.fit(X, y)\n",
    "print(predictor.score(X, y), \" accuracy on train set\")\n",
    "scores = cross_val_score(predictor, X, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean(), scores.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### XGBoost\n",
    "\n",
    "#### Multi softmax"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'objective': 'multi:softmax',\n",
       " 'use_label_encoder': True,\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'importance_type': 'gain',\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "clf = XGBClassifier(objective=\"multi:softmax\")\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[16:26:30] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fit\n",
      "0.8646057991852384  accuracy on train set\n",
      "[16:26:38] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fit\n",
      "[16:26:45] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fit\n",
      "[16:26:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fit\n",
      "[16:26:54] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fit\n",
      "[16:27:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fit\n",
      "[0.74610778 0.73413174 0.76287425 0.76858513 0.76378897]\n",
      "0.7550975746349029 0.00016766278645828764\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"Lowercase\", LowerCaseTransformer()),\n",
    "    (\"MentionFlagger\", MentionFlagger()),\n",
    "    (\"URLFlagger\", URLFlagger()),\n",
    "    (\"NumberFlagger\", NumberFlagger()),\n",
    "    (\"StopwordFilter\", StopWordFilter()),\n",
    "    (\"count\", CountVectorizer(analyzer=\"word\", tokenizer=split_punctuation, ngram_range=(1,3))),\n",
    "    (\"RF\", clf) # default\n",
    "])\n",
    "\n",
    "predictor = SmartPredictor(pipe=pipe)\n",
    "predictor.fit(X, y)\n",
    "print(predictor.score(X, y), \" accuracy on train set\")\n",
    "scores = cross_val_score(predictor, X, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean(), scores.var())"
   ]
  },
  {
   "source": [
    "#### Multi softprob"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'objective': 'multi:softprob',\n",
       " 'use_label_encoder': True,\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'importance_type': 'gain',\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "clf = XGBClassifier(objective=\"multi:softprob\")\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[16:27:05] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fit\n",
      "0.8646057991852384  accuracy on train set\n",
      "[16:27:10] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fit\n",
      "[16:27:14] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fit\n",
      "[16:27:19] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fit\n",
      "[16:27:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fit\n",
      "[16:27:29] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "fit\n",
      "[0.74610778 0.73413174 0.76287425 0.76858513 0.76378897]\n",
      "0.7550975746349029 0.00016766278645828764\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"Lowercase\", LowerCaseTransformer()),\n",
    "    (\"MentionFlagger\", MentionFlagger()),\n",
    "    (\"URLFlagger\", URLFlagger()),\n",
    "    (\"NumberFlagger\", NumberFlagger()),\n",
    "    (\"StopwordFilter\", StopWordFilter()),\n",
    "    (\"count\", CountVectorizer(analyzer=\"word\", tokenizer=split_punctuation, ngram_range=(1,3))),\n",
    "    (\"RF\", clf) # default\n",
    "])\n",
    "\n",
    "predictor = SmartPredictor(pipe=pipe)\n",
    "predictor.fit(X, y)\n",
    "print(predictor.score(X, y), \" accuracy on train set\")\n",
    "scores = cross_val_score(predictor, X, y, cv=5)\n",
    "print(scores)\n",
    "print(scores.mean(), scores.var())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "2a59e81c32054ab4392e844d7be1676fbd4800d80d366443e65330e6d0c4ec79"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}